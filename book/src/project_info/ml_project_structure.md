<h1>ðŸ“‚ Project Structure</h1>

```
gemma_local_trainer/
â”œâ”€â”€ Dockerfile              # Main training & inference environment
â”œâ”€â”€ Dockerfile.convert      # Separate environment for GGUF conversion
â”œâ”€â”€ README.md               # Project documentation (this file)
â”œâ”€â”€ demo.ipynb              # Interactive demonstration notebook
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/
â”‚   â””â”€â”€ emergency_dataset.jsonl
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ finetuned/          # Stores LoRA adapters and the final merged model
â”‚   â””â”€â”€ gguf/               # Stores quantized GGUF models
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ convert_to_gguf.py
â”‚   â””â”€â”€ inference_gguf.py
â””â”€â”€ src/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ config.py           # Centralized configuration
    â”œâ”€â”€ inference.py        # Inference script for the fine-tuned model
    â”œâ”€â”€ train_pipeline.py   # Main training and merging pipeline
    â””â”€â”€ utils.py
```